{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Variation Data Processing Notebook\n",
    "\n",
    "The purpose of this notebook is to annotate VOC data for further variationist analysis.  \n",
    "\n",
    "# 0.0 Creating a virtual environment with Conda\n",
    "\n",
    "A virtual environment in Python provides a self-contained and isolated environment for each project, allowing you to manage dependencies separately and avoid conflicts between different projects or system installations. It ensures reproducibility, simplifies dependency management, and promotes consistent environments across development stages without impacting the global Python environment.\n",
    "\n",
    "First create an environment called ``linguist258`` where you will download all necessary packages. You can either do it with conda or simply python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1A Conda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda create --name linguist258\n",
    "!conda activate linguist258\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1B Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m venv linguist258\n",
    "# Mac OS\n",
    "source env/bin/activate\n",
    "#Windows\n",
    "!.\\linguist258\\Scripts\\activate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Packages\n",
    "Once we have created and activated ``linguist258``, we will install the required packages on our computer. We only need to run this once, once they are installed they don't need to be installed again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pympi-ling\n",
      "  Downloading pympi_ling-1.70.2-py2.py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pympi-ling\n",
      "Successfully installed pympi-ling-1.70.2\n",
      "Requirement already satisfied: pandas in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (1.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: stanza in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: protobuf in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (from stanza) (4.23.4)\n",
      "Requirement already satisfied: requests in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (from stanza) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (from stanza) (4.62.3)\n",
      "Requirement already satisfied: torch>=1.3.0 in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (from stanza) (1.13.1)\n",
      "Requirement already satisfied: emoji in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (from stanza) (1.7.0)\n",
      "Requirement already satisfied: six in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (from stanza) (1.16.0)\n",
      "Requirement already satisfied: numpy in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (from stanza) (1.22.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.3.0->stanza) (4.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (from requests->stanza) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (from requests->stanza) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jesushermosillo/.local/lib/python3.9/site-packages (from requests->stanza) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jesushermosillo/opt/anaconda3/lib/python3.9/site-packages (from requests->stanza) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pympi-ling\n",
    "!pip install pandas\n",
    "!pip install stanza\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the imports necessary to run the rest of the cells. Cells from here down should be run in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympi import Eaf, Praat\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, replace the text in quotations the path in your computer where your .eaf or .TextGrid files are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_transcripts = Path(\"<path to folder where your recordings are located>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define a couple of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_annotations(tier_name, annotation_list, output_list):\n",
    "    \"\"\"This function formats a tuple of the form (begin, end, value)\n",
    "    into a list of dictionaries of the form {speaker, start, end, text}\"\"\"\n",
    "    \n",
    "    for start_ms, end_ms, text in annotation_list:\n",
    "\n",
    "        output_list.append({\n",
    "            'speaker': tier_name,\n",
    "            'start_ms': start_ms,\n",
    "            'end_ms': end_ms,\n",
    "            'text': text\n",
    "        })\n",
    "    \n",
    "    return output_list\n",
    "\n",
    "\n",
    "def get_annotations(root_path, filename, annotations=list(), tier_name=None):\n",
    "    \"\"\"Extracts all annotations for a given .eaf\n",
    "    file for a given tier (if tier_name specified) or for all tiers\"\"\"\n",
    "    # Load elan file\n",
    "    elan_object = Eaf(file_path=root_path / filename)\n",
    "    \n",
    "    # If a tier name is provided, only annotations for that\n",
    "    # tier will be used.\n",
    "    if tier_name:\n",
    "        tiernames = [tier_name]\n",
    "    else:\n",
    "        # Get all tier names\n",
    "        tiernames = elan_object.get_tier_names()\n",
    "\n",
    "    # Iterate over all tiers and extract annotations\n",
    "    for tier in tiernames:\n",
    "        \n",
    "        annotations = format_annotations(\n",
    "            tier,\n",
    "            elan_object.get_annotation_data_for_tier(tier),\n",
    "            annotations\n",
    "            )\n",
    "    return annotations\n",
    "    \n",
    "\n",
    "def iterate_over_folder(\n",
    "    root_path, annotations=list(),\n",
    "    file_extension='.eaf', # This parameter can't really be changes with the code as is.\n",
    "    output_format='dict_list',\n",
    "    tier_name=None\n",
    "    ):\n",
    "    \"\"\"Iterates over files of a specified extensions and \n",
    "    extracts annotations into either a list of dictionaries\n",
    "    or a pandas dataframe.\"\"\"\n",
    "    for file in root_path.glob(f'*{file_extension}'):\n",
    "        \n",
    "        annotations = get_annotations(\n",
    "            root_path, file,\n",
    "            annotations=annotations,\n",
    "            tier_name=tier_name\n",
    "            )\n",
    "    \n",
    "    \n",
    "    if output_format == 'pandas':\n",
    "        return pd.DataFrame(annotations)\n",
    "    elif output_format == 'dict_list':\n",
    "        return annotations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are utilities to write annotations into elan or praat once they have been processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tier name can probably be derived from annotations. \n",
    "# I can change this once we have a better idea of the \n",
    "# output structure.\n",
    "def output_tier(eaf_object, tier_name, annotation_name, annotation_list):\n",
    "    \n",
    "    eaf_object.add_tier(tier_name)\n",
    "    \n",
    "    for annotation_dict in annotation_list:\n",
    "        \n",
    "        \n",
    "        eaf_object.add_annotation(\n",
    "            tier_name, \n",
    "            annotation_dict['start_ms'],\n",
    "            annotation_dict['end_ms'],\n",
    "            value=annotation_dict[annotation_name] # Probably somethign like 'pos_tags'\n",
    "            )\n",
    "    \n",
    "    return eaf_object\n",
    "\n",
    "\n",
    "def write_eaf(eaf_object, output_file):\n",
    "    \n",
    "    eaf_object.to_file(output_file)\n",
    "        \n",
    "###################################################################################\n",
    "###################################################################################\n",
    "####### Praat functionality can be added if necessary to both #####################\n",
    "####### input and output pipelines.                           #####################\n",
    "###################################################################################\n",
    "###################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Linguistic Annotation\n",
    "\n",
    "We begin by importing the stanza package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now download the necessary packages from stanza. This should only be done once. \n",
    "\n",
    "The first argument ``en`` is the language code for English, and the processors include a tokenizer, part of speech tagger, and a lemmatizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae5cc73b1244562973313bf2c97e8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 10:06:28 INFO: Downloading these customized packages for language: en (English)...\n",
      "==============================\n",
      "| Processor       | Package  |\n",
      "------------------------------\n",
      "| tokenize        | combined |\n",
      "| pos             | combined |\n",
      "| lemma           | combined |\n",
      "| pretrain        | combined |\n",
      "| backward_charlm | 1billion |\n",
      "| forward_charlm  | 1billion |\n",
      "==============================\n",
      "\n",
      "2024-04-30 10:06:28 INFO: File exists: /Users/jesushermosillo/stanza_resources/en/tokenize/combined.pt\n",
      "2024-04-30 10:06:28 INFO: File exists: /Users/jesushermosillo/stanza_resources/en/pos/combined.pt\n",
      "2024-04-30 10:06:28 INFO: File exists: /Users/jesushermosillo/stanza_resources/en/lemma/combined.pt\n",
      "2024-04-30 10:06:28 INFO: File exists: /Users/jesushermosillo/stanza_resources/en/pretrain/combined.pt\n",
      "2024-04-30 10:06:28 INFO: File exists: /Users/jesushermosillo/stanza_resources/en/backward_charlm/1billion.pt\n",
      "2024-04-30 10:06:28 INFO: File exists: /Users/jesushermosillo/stanza_resources/en/forward_charlm/1billion.pt\n",
      "2024-04-30 10:06:28 INFO: Finished downloading models and saved to /Users/jesushermosillo/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "stanza.download('en', processors='tokenize,pos,lemma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we download the necessary stanza packages, we initialize the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 10:10:30 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df218a26dc24944a7d0b10473cef796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 10:10:30 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2024-04-30 10:10:31 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "========================\n",
      "\n",
      "2024-04-30 10:10:31 INFO: Use device: cpu\n",
      "2024-04-30 10:10:31 INFO: Loading: tokenize\n",
      "2024-04-30 10:10:31 INFO: Loading: pos\n",
      "2024-04-30 10:10:31 INFO: Loading: lemma\n",
      "2024-04-30 10:10:31 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('en',\n",
    "                      use_gpu=False, \n",
    "                      processors=['tokenize','pos','lemma','mwt'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitue with actual path to the data\n",
    "df = pd.read_csv('Transcriptions/toy_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now annotate the utterances using ``nlp()``. The ``apply()`` function allows us to apply a function to a column in a pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['annotated'] = df.text.apply(lambda x: nlp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMA_Stepney_SarahA', 0, 2294, 'so', 'RB', None]\n",
      "['AMA_Stepney_SarahA', 0, 2294, 'being', 'VBG', 'VerbForm=Ger']\n",
      "['AMA_Stepney_SarahA', 0, 2294, '..', ',', None]\n",
      "['AMA_Stepney_SarahA', 0, 2294, 'introduced', 'VBN', 'Tense=Past|VerbForm=Part']\n",
      "['AMA_Stepney_SarahA', 0, 2294, 'like', 'IN', None]\n",
      "['AMA_Stepney_SarahA', 0, 2294, 'an', 'DT', 'Definite=Ind|PronType=Art']\n",
      "['AMA_Stepney_SarahA', 0, 2294, 'actual', 'JJ', 'Degree=Pos']\n",
      "['AMA_Stepney_SarahA', 0, 2294, ',', ',', None]\n",
      "\n",
      "['AMA_Stepney_SarahA', 270165, 270655, 'yeah', 'UH', None]\n",
      "['AMA_Stepney_SarahA', 270165, 270655, ',', ',', None]\n",
      "\n",
      "['AMA_Stepney_SarahA', 272560, 273470, 'yeah', 'UH', None]\n",
      "['AMA_Stepney_SarahA', 272560, 273470, ',', ',', None]\n",
      "\n",
      "['AMA_Stepney_SarahA', 282355, 285675, 'uhm', 'UH', None]\n",
      "['AMA_Stepney_SarahA', 282355, 285675, 'yeah', 'UH', None]\n",
      "['AMA_Stepney_SarahA', 282355, 285675, 'they', 'PRP', 'Case=Nom|Number=Plur|Person=3|PronType=Prs']\n",
      "['AMA_Stepney_SarahA', 282355, 285675, 'all', 'DT', None]\n",
      "['AMA_Stepney_SarahA', 282355, 285675, '-', ',', None]\n",
      "['AMA_Stepney_SarahA', 282355, 285675, 'they', 'PRP', 'Case=Nom|Number=Plur|Person=3|PronType=Prs']\n",
      "['AMA_Stepney_SarahA', 282355, 285675, 'all', 'DT', None]\n",
      "['AMA_Stepney_SarahA', 282355, 285675, 'came', 'VBD', 'Mood=Ind|Number=Plur|Person=3|Tense=Past|VerbForm=Fin']\n",
      "['AMA_Stepney_SarahA', 282355, 285675, 'from', 'IN', None]\n",
      "['AMA_Stepney_SarahA', 282355, 285675, 'uh', 'UH', None]\n",
      "['AMA_Stepney_SarahA', 282355, 285675, '-', ',', None]\n",
      "\n",
      "['AMA_Stepney_SarahA', 285685, 286305, 'uhm', 'UH', None]\n",
      "['AMA_Stepney_SarahA', 285685, 286305, ',', ',', None]\n",
      "\n",
      "['AMA_Stepney_SarahA', 286535, 288065, 'families', 'NNS', 'Number=Plur']\n",
      "['AMA_Stepney_SarahA', 286535, 288065, 'that', 'WDT', 'PronType=Rel']\n",
      "['AMA_Stepney_SarahA', 286535, 288065, 'had', 'VBD', 'Mood=Ind|Number=Plur|Person=3|Tense=Past|VerbForm=Fin']\n",
      "['AMA_Stepney_SarahA', 286535, 288065, 'a', 'DT', 'Definite=Ind|PronType=Art']\n",
      "['AMA_Stepney_SarahA', 286535, 288065, 'lot', 'NN', 'Number=Sing']\n",
      "['AMA_Stepney_SarahA', 286535, 288065, 'of', 'IN', None]\n",
      "['AMA_Stepney_SarahA', 286535, 288065, 'money', 'NN', 'Number=Sing']\n",
      "['AMA_Stepney_SarahA', 286535, 288065, ',', ',', None]\n",
      "\n",
      "['AMA_Stepney_SarahA', 288370, 290980, 'uh', 'UH', None]\n",
      "['AMA_Stepney_SarahA', 288370, 290980, ':', ':', None]\n",
      "['AMA_Stepney_SarahA', 288370, 290980, 'you', 'PRP', 'Case=Nom|Person=2|PronType=Prs']\n",
      "['AMA_Stepney_SarahA', 288370, 290980, 'could', 'MD', 'VerbForm=Fin']\n",
      "['AMA_Stepney_SarahA', 288370, 290980, \"n't\", 'RB', None]\n",
      "['AMA_Stepney_SarahA', 288370, 290980, 'really', 'RB', None]\n",
      "['AMA_Stepney_SarahA', 288370, 290980, 'tell', 'VB', 'VerbForm=Inf']\n",
      "['AMA_Stepney_SarahA', 288370, 290980, 'though', 'RB', None]\n",
      "['AMA_Stepney_SarahA', 288370, 290980, 'cuz', 'IN', None]\n",
      "['AMA_Stepney_SarahA', 288370, 290980, 'they', 'PRP', 'Case=Nom|Number=Plur|Person=3|PronType=Prs']\n",
      "['AMA_Stepney_SarahA', 288370, 290980, 'a', 'MD', 'Mood=Ind|Person=3|Tense=Pres|VerbForm=Fin']\n",
      "['AMA_Stepney_SarahA', 288370, 290980, '...', '.', None]\n",
      "\n",
      "['AMA_Stepney_SarahA', 291205, 292555, '@but', 'LS', None]\n",
      "['AMA_Stepney_SarahA', 291205, 292555, '@yeah', 'NNP', 'Number=Sing']\n",
      "\n",
      "['AMA_Stepney_SarahA', 292610, 294870, 'yeah', 'UH', None]\n",
      "['AMA_Stepney_SarahA', 292610, 294870, 'so', 'RB', None]\n",
      "['AMA_Stepney_SarahA', 292610, 294870, 'you', 'PRP', 'Case=Nom|Person=2|PronType=Prs']\n",
      "['AMA_Stepney_SarahA', 292610, 294870, 'could', 'MD', 'VerbForm=Fin']\n",
      "['AMA_Stepney_SarahA', 292610, 294870, \"n't\", 'RB', None]\n",
      "['AMA_Stepney_SarahA', 292610, 294870, 'really', 'RB', None]\n",
      "['AMA_Stepney_SarahA', 292610, 294870, 'tell', 'VB', 'VerbForm=Inf']\n",
      "['AMA_Stepney_SarahA', 292610, 294870, 'but', 'CC', None]\n",
      "['AMA_Stepney_SarahA', 292610, 294870, 'they', 'PRP', 'Case=Nom|Number=Plur|Person=3|PronType=Prs']\n",
      "['AMA_Stepney_SarahA', 292610, 294870, 'all', 'DT', None]\n",
      "['AMA_Stepney_SarahA', 292610, 294870, '...', '.', None]\n",
      "\n",
      "['AMA_Stepney_SarahA', 294960, 298910, 'their', 'PRP$', 'Number=Plur|Person=3|Poss=Yes|PronType=Prs']\n",
      "['AMA_Stepney_SarahA', 294960, 298910, 'families', 'NNS', 'Number=Plur']\n",
      "['AMA_Stepney_SarahA', 294960, 298910, 'own', 'VBP', 'Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin']\n",
      "['AMA_Stepney_SarahA', 294960, 298910, 'land', 'NN', 'Number=Sing']\n",
      "['AMA_Stepney_SarahA', 294960, 298910, 'have', 'VBP', 'Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin']\n",
      "['AMA_Stepney_SarahA', 294960, 298910, 'businesses', 'NNS', 'Number=Plur']\n",
      "['AMA_Stepney_SarahA', 294960, 298910, 'all', 'DT', None]\n",
      "['AMA_Stepney_SarahA', 294960, 298910, 'th', 'UH', None]\n",
      "['AMA_Stepney_SarahA', 294960, 298910, '...', '.', None]\n",
      "\n",
      "['AMA_Stepney_SarahA', 299605, 299975, 'so', 'RB', None]\n",
      "['AMA_Stepney_SarahA', 299605, 299975, ',', ',', None]\n",
      "\n",
      "['Interviewer', 270790, 273530, 'I', 'PRP', 'Case=Nom|Number=Sing|Person=1|PronType=Prs']\n",
      "['Interviewer', 270790, 273530, \"'m\", 'VBP', 'Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin']\n",
      "['Interviewer', 270790, 273530, 'so', 'RB', None]\n",
      "['Interviewer', 270790, 273530, 'sorry', 'JJ', 'Degree=Pos']\n",
      "['Interviewer', 270790, 273530, 'you', 'PRP', 'Case=Nom|Person=2|PronType=Prs']\n",
      "['Interviewer', 270790, 273530, 'had', 'VBD', 'Mood=Ind|Number=Sing|Person=2|Tense=Past|VerbForm=Fin']\n",
      "['Interviewer', 270790, 273530, 'to', 'TO', None]\n",
      "['Interviewer', 270790, 273530, 'do', 'VB', 'VerbForm=Inf']\n",
      "['Interviewer', 270790, 273530, 'all', 'DT', None]\n",
      "['Interviewer', 270790, 273530, 'of', 'IN', None]\n",
      "['Interviewer', 270790, 273530, 'that', 'DT', 'Number=Sing|PronType=Dem']\n",
      "['Interviewer', 270790, 273530, 'la:bor', 'NN', 'Number=Sing']\n",
      "['Interviewer', 270790, 273530, '.', '.', None]\n",
      "\n",
      "['Interviewer', 273675, 274305, 'wow', 'UH', None]\n",
      "['Interviewer', 273675, 274305, ',', ',', None]\n",
      "\n",
      "['Interviewer', 274940, 278250, 'uh', 'UH', None]\n",
      "['Interviewer', 274940, 278250, 'was', 'VBD', 'Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin']\n",
      "['Interviewer', 274940, 278250, ':', ':', None]\n",
      "['Interviewer', 274940, 278250, ',', ',', None]\n",
      "['Interviewer', 274940, 278250, 'how', 'WRB', 'PronType=Int']\n",
      "['Interviewer', 274940, 278250, 'about', 'IN', None]\n",
      "['Interviewer', 274940, 278250, 'money', 'NN', 'Number=Sing']\n",
      "['Interviewer', 274940, 278250, '?', '.', None]\n",
      "['Interviewer', 274940, 278250, 'was', 'VBD', 'Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin']\n",
      "['Interviewer', 274940, 278250, 'money', 'NN', 'Number=Sing']\n",
      "['Interviewer', 274940, 278250, 'a', 'NN', 'Number=Sing']\n",
      "['Interviewer', 274940, 278250, ',', ',', None]\n",
      "\n",
      "['Interviewer', 278385, 279495, 'big', 'JJ', 'Degree=Pos']\n",
      "['Interviewer', 278385, 279495, 'issue', 'NN', 'Number=Sing']\n",
      "['Interviewer', 278385, 279495, 'in', 'IN', None]\n",
      "['Interviewer', 278385, 279495, ',', ',', None]\n",
      "\n",
      "['Interviewer', 279710, 282260, 'your', 'PRP$', 'Person=2|Poss=Yes|PronType=Prs']\n",
      "['Interviewer', 279710, 282260, 'High', 'JJ', 'Degree=Pos']\n",
      "['Interviewer', 279710, 282260, 'School', 'NNP', 'Number=Sing']\n",
      "['Interviewer', 279710, 282260, 'like', 'NN', 'Number=Sing']\n",
      "['Interviewer', 279710, 282260, 'were', 'VBD', 'Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin']\n",
      "['Interviewer', 279710, 282260, 'there', 'RB', 'PronType=Dem']\n",
      "['Interviewer', 279710, 282260, 'rich', 'JJ', 'Degree=Pos']\n",
      "['Interviewer', 279710, 282260, 'kids', 'NNS', 'Number=Plur']\n",
      "['Interviewer', 279710, 282260, 'and', 'CC', None]\n",
      "['Interviewer', 279710, 282260, '-', ',', None]\n",
      "\n",
      "['Interviewer', 298935, 299575, 'm', 'NNP', 'Number=Sing']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotated_data = []\n",
    "for speaker,start_ms,end_ms, sentences in np.array(df[ ['speaker', 'start_ms', 'end_ms', 'annotated']]):\n",
    "    for sent in sentences.sentences:\n",
    "        for word in sent.words:\n",
    "            annotation = [speaker,start_ms, end_ms, word.text, word.xpos, word.feats]\n",
    "            annotated_data.append(annotation)\n",
    "            print(annotation)\n",
    "    print() \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df = pd.DataFrame(annotated_data,\n",
    "                            columns=['speaker', 'start_ms', 'end_ms', 'Word','POS','Features'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>start_ms</th>\n",
       "      <th>end_ms</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMA_Stepney_SarahA</td>\n",
       "      <td>0</td>\n",
       "      <td>2294</td>\n",
       "      <td>so</td>\n",
       "      <td>RB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMA_Stepney_SarahA</td>\n",
       "      <td>0</td>\n",
       "      <td>2294</td>\n",
       "      <td>being</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VerbForm=Ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMA_Stepney_SarahA</td>\n",
       "      <td>0</td>\n",
       "      <td>2294</td>\n",
       "      <td>..</td>\n",
       "      <td>,</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMA_Stepney_SarahA</td>\n",
       "      <td>0</td>\n",
       "      <td>2294</td>\n",
       "      <td>introduced</td>\n",
       "      <td>VBN</td>\n",
       "      <td>Tense=Past|VerbForm=Part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMA_Stepney_SarahA</td>\n",
       "      <td>0</td>\n",
       "      <td>2294</td>\n",
       "      <td>like</td>\n",
       "      <td>IN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Interviewer</td>\n",
       "      <td>279710</td>\n",
       "      <td>282260</td>\n",
       "      <td>rich</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Degree=Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Interviewer</td>\n",
       "      <td>279710</td>\n",
       "      <td>282260</td>\n",
       "      <td>kids</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Number=Plur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Interviewer</td>\n",
       "      <td>279710</td>\n",
       "      <td>282260</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Interviewer</td>\n",
       "      <td>279710</td>\n",
       "      <td>282260</td>\n",
       "      <td>-</td>\n",
       "      <td>,</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Interviewer</td>\n",
       "      <td>298935</td>\n",
       "      <td>299575</td>\n",
       "      <td>m</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                speaker  start_ms  end_ms        Word  POS  \\\n",
       "0    AMA_Stepney_SarahA         0    2294          so   RB   \n",
       "1    AMA_Stepney_SarahA         0    2294       being  VBG   \n",
       "2    AMA_Stepney_SarahA         0    2294          ..    ,   \n",
       "3    AMA_Stepney_SarahA         0    2294  introduced  VBN   \n",
       "4    AMA_Stepney_SarahA         0    2294        like   IN   \n",
       "..                  ...       ...     ...         ...  ...   \n",
       "106         Interviewer    279710  282260        rich   JJ   \n",
       "107         Interviewer    279710  282260        kids  NNS   \n",
       "108         Interviewer    279710  282260         and   CC   \n",
       "109         Interviewer    279710  282260           -    ,   \n",
       "110         Interviewer    298935  299575           m  NNP   \n",
       "\n",
       "                     Features  \n",
       "0                        None  \n",
       "1                VerbForm=Ger  \n",
       "2                        None  \n",
       "3    Tense=Past|VerbForm=Part  \n",
       "4                        None  \n",
       "..                        ...  \n",
       "106                Degree=Pos  \n",
       "107               Number=Plur  \n",
       "108                      None  \n",
       "109                      None  \n",
       "110               Number=Sing  \n",
       "\n",
       "[111 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see all adjectives in the data using the following line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>start_ms</th>\n",
       "      <th>end_ms</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMA_Stepney_SarahA</td>\n",
       "      <td>0</td>\n",
       "      <td>2294</td>\n",
       "      <td>actual</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Degree=Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Interviewer</td>\n",
       "      <td>270790</td>\n",
       "      <td>273530</td>\n",
       "      <td>sorry</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Degree=Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Interviewer</td>\n",
       "      <td>278385</td>\n",
       "      <td>279495</td>\n",
       "      <td>big</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Degree=Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Interviewer</td>\n",
       "      <td>279710</td>\n",
       "      <td>282260</td>\n",
       "      <td>High</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Degree=Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Interviewer</td>\n",
       "      <td>279710</td>\n",
       "      <td>282260</td>\n",
       "      <td>rich</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Degree=Pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                speaker  start_ms  end_ms    Word POS    Features\n",
       "6    AMA_Stepney_SarahA         0    2294  actual  JJ  Degree=Pos\n",
       "72          Interviewer    270790  273530   sorry  JJ  Degree=Pos\n",
       "96          Interviewer    278385  279495     big  JJ  Degree=Pos\n",
       "101         Interviewer    279710  282260    High  JJ  Degree=Pos\n",
       "106         Interviewer    279710  282260    rich  JJ  Degree=Pos"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_df[annotated_df.POS=='JJ']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
